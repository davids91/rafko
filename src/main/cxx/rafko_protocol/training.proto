/*! This file is part of davids91/Rafko.
 *
 *    Rafko is free software: you can redistribute it and/or modify
 *    it under the terms of the GNU General Public License as published by
 *    the Free Software Foundation, either version 3 of the License, or
 *    (at your option) any later version.
 *
 *    Rafko is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    GNU General Public License for more details.
 *
 *    You should have received a copy of the GNU General Public License
 *    along with Rafko.  If not, see <https://www.gnu.org/licenses/> or
 *    <https://github.com/davids91/rafko/blob/master/LICENSE>
 */

syntax = "proto3";
option cc_enable_arenas = true;
option java_package = "org.rafko.rafko_gym";
option java_outer_classname = "RafkoTraining";
package rafko_gym;

import "rafko_net.proto";

/** @brief      Indexes of the error functions a Neural Network is able to use
 *              to calculate the gradient of the weights
 */
enum Cost_functions{
  cost_function_unknown = 0;
  cost_function_squared_error = 1;          /* ( (expected-calculated)^2 ) */
  cost_function_mse = 2;                    /* ( 0.5*(expected-calculated)^2 ) / dataset_size */
  cost_function_cross_entropy = 3;          /* ( calculated*ln(expected) ) */
  cost_function_binary_cross_entropy = 4;   /* ( calculated*ln(expected) + (1-calculated) * ln(1-expected) ) */
}

/** @brief      Describes the available weight updaters implemented in the framework
 */
enum Weight_updaters{
  weight_updater_unknown = 0;
  weight_updater_default = 1;
  weight_updater_momentum = 2;
  weight_updater_nesterovs = 3;
  weight_updater_adam = 4;
  weight_updater_amsgrad = 5;
  weight_updater_end = 512;
}

/** @brief      Different configurable strategies while training
 */
enum Training_strategy{
  training_strategy_unknown = 0;
  training_strategy_early_stopping = 1; /* Stop the training when training eror diverges from test error */
  training_strategy_learning_rate_schedule = 2;
  training_strategy_stochastic_mining_schedule = 4;
  training_strategy_stop_if_training_error_below_learning_rate = 4096;
  training_strategy_stop_if_training_error_zero = 8192;
  training_strategy_end = 1048576;
}

enum Autodiff_operations{
  ad_operation_unknown = 0;
  ad_operation_objective_d = 1;
  ad_operation_neuron_spike_d = 2;
  ad_operation_neuron_transfer_d = 3;
  ad_operation_neuron_input_d = 4;
  ad_operation_neuron_bias_d = 5;
  ad_operation_network_input_d = 6;

  /* Feature operations are indirectly modifying derivatives */
  ad_operation_network_weight_regularization_feature = 20;
  ad_operation_network_feature = 21;
}

/**
 * @brief      Service hyperparameters describe the context in which deep learning services
 *             operate. It contains all the neccessary set of variables to function in the
 *             context of deep learning. System relevant parameters like the number of working threads
 *             are decided from the server configuration.
 */
message TrainingHyperparameters{
  double learning_rate = 10;
  uint32 minibatch_size = 11;
  uint32 memory_truncation = 12;
  rafko_gym.Training_strategy training_strategies = 13;

  double alpha = 20;
  double beta = 21;
  double gamma = 22;
  double delta = 23;
  double epsilon = 24; /* very small positive value almost greater, than zero */
  double zetta = 25; /* Commonly used for oscillation dampening purposes */
  double lambda = 31;
  double beta_2 = 45; /* a second alphabet shall be started for algorithms requiring two variants of parameters */
}

/** @brief      Describes a data-set to train or test Neural Networks
 *              The input and label arrays contain @input_size and @feature_size floating point numbers
 *              respectively, repeated after one another.
 *              In case of sequential data, label-input pairs of @sequence_size are considered one sequence.
 *              By desgin the number of  @labels should  be a multiple of @sequence_size * @feature_size.
 */
message DataSet{
  uint32 input_size = 1;
  uint32 feature_size = 2;
  uint32 sequence_size = 3;
  repeated double inputs = 10;
  repeated double labels = 11;
}

/**
 * @brief      An incomplete update value to the vector of a @RafkoNet.
 *             It contains some gradient values to update a corresponding
 *             network. A fragment can be calculated from a host, then it can be used to
 *             update or partially update a network.
 */
message NetworkWeightVectorDelta{
  repeated rafko_net.IndexSynapseInterval weight_synapses = 1; /* The index values of the weights ( in the @RafkoNet ) for the values stored in the fragment */
  repeated double values = 2; /* Weight update values inside the fragment. The values follow one another in the order they appear based on the @weight_synapses member */
}
