/*! This file is part of davids91/Rafko.
 *
 *    Rafko is free software: you can redistribute it and/or modify
 *    it under the terms of the GNU General Public License as published by
 *    the Free Software Foundation, either version 3 of the License, or
 *    (at your option) any later version.
 *
 *    Rafko is distributed in the hope that it will be useful,
 *    but WITHOUT ANY WARRANTY; without even the implied warranty of
 *    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 *    GNU General Public License for more details.
 *
 *    You should have received a copy of the GNU General Public License
 *    along with Rafko.  If not, see <https://www.gnu.org/licenses/> or
 *    <https://github.com/davids91/rafko/blob/master/LICENSE>
 */

syntax = "proto3";
option cc_enable_arenas = true;
option java_package = "org.rafko.sparse_net_library";
option java_outer_classname = "RafkoSparseNet";
package sparse_net_library;

import "common.proto";

/** @brief      Network basically describes the connections a recurrent network has
 *              with the past runs. This enumeration is for a utility which is for
 *              testing purposes only. Recurrences described here affect
 *              only the rpc @build_network in the service @Rafko_deep_learning
 */
enum Network_recurrence{
  NETWORK_RECURRENCE_UNKNOWN = 0;
  NETWORK_RECURRENCE_TO_SELF = 1;
  NETWORK_RECURRENCE_TO_LAYER = 2;
}

/** @brief      Takes input, assignes weights to them and processes
 *              the weigthed sums with a bias, transfer function and a memory filter.
 */
message Neuron{
  /* index of the weight for the memory filter. 1.0: keep its previous value instead of the newly calculated one */
  uint32 memory_filter_idx = 2;  /* Value pointed at should always be 0.0 <= memory_filter < 1.0 default value is 0.0 <== as in zero memory of its previous value */
  transfer_functions transfer_function_idx = 3; /* index of the transfer funtion this Neuron uses, empty is invalid */

  /**
   * Input weights shall only contain positive intervals,
   * each interval corresponding to an index in the @weight_table in the @SparseNet
   * Every weight above inputs in @input_indices count as a bias, and shall behave 
   * like it has an input of 1.
   */
  repeated Index_synapse_interval input_weights = 10;

  /**
   * Input indices describes intervals denoting the neurons inputs.
   * Each positive interval corresponds to indices in the internal data of a @Neuron stored in the @Solution_solver
   * Each negative interval corresponds to indices in the input data given to the @Solution_solver
   */
  repeated Input_synapse_interval input_indices = 11;
}

/** @brief      A sparse net implementation containing the
 *              Neurons and optimization cache files
 */
message SparseNet{
  uint32 input_data_size = 10; /* Number of inputs (floating point numbers) accepted by the Neural network */
  uint32 output_neuron_number = 11; /* Number of outputs the Neural network has */

  repeated Neuron neuron_array = 20; /* Array of Neurons the network has */
  repeated double weight_table = 21; /* Stores induvidual weights used by the Neurons */
}
